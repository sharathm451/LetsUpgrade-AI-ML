{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use digit dataset and perform LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "print(digits.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(digits.data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = digits.feature_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of training set: 1.000\n",
      "Accuracy score of testing set: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(digits.data, digits.target, stratify = digits.target, random_state = 2, test_size = 0.3)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print('Accuracy score of training set: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
    "print('Accuracy score of testing set: {:.3f}'.format(log_reg.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_pred\n",
       "0       4       4\n",
       "1       0       0\n",
       "2       4       4\n",
       "3       3       3\n",
       "4       5       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame() \n",
    "df['y_test'] = y_test\n",
    "df['y_pred'] = y_pred\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total no. of mislabelled datapoints from 540 test sample is 24 \n"
     ]
    }
   ],
   "source": [
    "mislabel = np.sum(y_test != y_pred)\n",
    "print(\"the total no. of mislabelled datapoints from {} test sample is {} \".format(len(y_test),mislabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "516/540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy is:{Accuracy:4.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "x = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 2, test_size = 0.2)\n",
    "\n",
    "dct= DecisionTreeClassifier(random_state=0)\n",
    "dct.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dct.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 9, 1, 9, 7, 1, 5, 1, 6, 6, 7, 6, 2, 5, 5, 9, 6, 2, 7, 4, 6,\n",
       "       4, 1, 5, 2, 9, 5, 4, 6, 5, 6, 3, 8, 0, 8, 5, 8, 0, 6, 8, 1, 5, 7,\n",
       "       9, 6, 9, 6, 1, 3, 0, 1, 9, 7, 3, 3, 1, 1, 8, 1, 9, 8, 5, 9, 9, 1,\n",
       "       7, 5, 8, 4, 3, 9, 3, 8, 7, 3, 3, 0, 8, 7, 2, 1, 5, 8, 8, 7, 6, 4,\n",
       "       6, 2, 2, 0, 1, 1, 5, 3, 5, 7, 7, 8, 2, 8, 6, 4, 6, 7, 3, 7, 3, 8,\n",
       "       4, 7, 0, 9, 5, 2, 5, 9, 3, 9, 2, 8, 5, 2, 0, 8, 1, 9, 2, 1, 3, 1,\n",
       "       0, 3, 4, 8, 0, 9, 3, 2, 2, 7, 3, 1, 2, 7, 2, 8, 3, 1, 1, 6, 4, 8,\n",
       "       2, 1, 8, 4, 8, 3, 7, 1, 9, 3, 4, 9, 7, 4, 8, 9, 5, 7, 6, 9, 8, 0,\n",
       "       4, 0, 0, 9, 0, 6, 5, 8, 8, 9, 7, 7, 2, 0, 8, 3, 7, 3, 0, 2, 1, 8,\n",
       "       2, 7, 0, 6, 9, 3, 3, 1, 3, 5, 2, 8, 5, 2, 1, 2, 9, 4, 6, 5, 5, 5,\n",
       "       9, 7, 1, 3, 9, 6, 3, 7, 1, 7, 5, 8, 7, 6, 4, 5, 5, 4, 2, 6, 6, 2,\n",
       "       2, 4, 3, 7, 7, 0, 9, 5, 7, 4, 3, 4, 1, 0, 3, 3, 5, 4, 1, 9, 1, 2,\n",
       "       5, 1, 4, 0, 9, 1, 5, 5, 7, 4, 0, 1, 0, 3, 5, 5, 5, 4, 0, 7, 8, 6,\n",
       "       2, 1, 1, 1, 7, 9, 4, 7, 9, 7, 0, 4, 9, 6, 9, 2, 7, 2, 1, 0, 8, 2,\n",
       "       8, 6, 5, 7, 8, 4, 5, 7, 8, 6, 4, 2, 6, 9, 3, 0, 0, 8, 0, 6, 4, 7,\n",
       "       1, 7, 5, 6, 9, 7, 2, 8, 3, 1, 2, 4, 1, 8, 8, 7, 6, 0, 8, 0, 6, 8,\n",
       "       5, 7, 8, 0, 4, 1, 4, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.833333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy:{Accuracy:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cmdf = pd.DataFrame(cm,index = digits.target_names,columns=digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9\n",
       "0  30   0   0   0   0   0   0   0   1   1\n",
       "1   0  37   1   1   0   0   0   2   2   1\n",
       "2   0   0  28   1   0   0   1   0   1   0\n",
       "3   0   0   0  26   0   1   0   1   4   4\n",
       "4   1   1   0   0  26   0   0   1   1   5\n",
       "5   0   0   0   3   1  36   0   0   3   0\n",
       "6   0   0   1   0   2   0  31   1   0   0\n",
       "7   0   1   0   0   2   0   0  36   1   0\n",
       "8   0   3   3   1   0   0   0   1  27   1\n",
       "9   0   0   0   1   0   1   0   1   2  23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8377095353597456"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428485372635451"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96774194, 0.88095238, 0.84848485, 0.78787879, 0.83870968,\n",
       "       0.94736842, 0.96875   , 0.8372093 , 0.64285714, 0.65714286])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96774194, 0.88095238, 0.84848485, 0.78787879, 0.83870968,\n",
       "       0.94736842, 0.96875   , 0.8372093 , 0.64285714, 0.65714286])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average=None, zero_division=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi class precision avg is getting not possible here,so wanna make into simple classifier with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits() \n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples,n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)] \n",
    "\n",
    "\n",
    "# Limit to the two first classes, and split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[y < 2], y[y < 2],\n",
    "                                                    test_size=.5,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "# Create a simple classifier\n",
    "classifier = svm.LinearSVC(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.decision_function(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And here goes average precision for multi class target variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Precision-Recall curve¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=1.00')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi+0lEQVR4nO3de5gU5Z328e8tZwXFyOAqIKAQkSCyOouaiBFNPBAVRSMQEhKWRPEQ85qYN8Y3WXFXN2bfLFE3UWKCUSOCLh5JPMQoxuhKBAQRggpRlAHUEQVUjoO//aNqxmaoYXpgenoO9+e6+pqpeqqrf09PT99VT1VXKyIwMzOrbo9iF2BmZo2TA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSCaKUnfkPRMseuoT5LGSPpjHstNlvTjhqipIUhaLukL6e8TJd1Z7JqsZXBANCKS2kmaIukNSR9Imi/ptGLXlY/0TWyjpA8lvS3pt5I61udjRMTUiDg5j+UmRMS/1edjV5IUkj5K+7lS0iRJrQrxWM2dpNskVUg6sNr8iZK2ps/xWkn/I+nYOq77AEkPSVqV/s161bJ8L0mzJG2Q9HJlIOe0fyX9v/xI0gOSPlWXepoqB0Tj0hpYAXwe2Af4MXBPbS/uRuSMiOgIHAn8E/Cj6gtIat3gVdW/I9J+fh4YCfxzkeupVw3xN5K0F3AOsA4Yk7HI3elzXAI8A9wnSXV4iI+BR9PHyMc0YD6wH/D/gBmSStJaPwP8CvgasD+wAbipDrU0WQ6IRiQiPoqIiRGxPCI+jojfA68DR9V0H0k9JN0nqVzSGkm/qGG5GyStkLRe0jxJQ3LaBkuam7a9LWlSOr+9pDvT9a6VNEfS/nn0YyXwCDAgXU9IuljSUmBpOu90SQtythAH1tan3GEzJX4u6R1J6yQtlFT5eLdJuiZnfd+StEzSe+lW5YE5bSFpgqSlkt6X9Mt834giYhnwLDAoZ3270q9DJD2ZzntX0lRJnfOpoTpJw9PHXy/p75JOTedXDVOl01VDVenWc0gaL+lN4ElJj0q6pNq6X5Q0Iv29n6TH0+f0FUnn1bHUc4C1wL8CX69poYjYCtwO/APJm3deIuLtiLgJmFPbspI+TbJRc1VEbIyIe4GX+CRcxgAzI+LpiPiQZMNthKRO+dbTVDkgGrH0zfjTwOIa2lsBvwfeAHoB3YDpNaxuDskb2aeAu4D/ltQ+bbsBuCEi9gYOAe5J53+dZE+mB8k/5wRgYx519wCGkWyRVToLOBroL+lI4FbggnS9vwIeUjLElm+fTgaOJ3l+OpNsya/JqOVE4CfAecAB6Xqrr+90kj2eI9LlTqmtj+m6+wFDgGXp9K72S2mNBwKHkTzfE/OpoVo9g4E7gO+TPCfHA8vrsIrPp49/CslrZHTOuvsDPYE/pFv/j6fLdE2Xuynd0q4cjllYy2N9nWSrfTrQL33usvrUDvgGUBYR70o6Lg3fmm7H1aG/lT4DvBYRH+TMezGdX9n+YmVDRPwd2ELy2mvWHBCNlKQ2wFTg9oh4uYbFBpO8qXw/3fvYFBGZB6Yj4s6IWBMRFRHxn0A74NC0eSvQR1KXiPgwImbnzN8P6BMR2yJiXkSs30nZD0haSzIk8Gfg33PafhIR70XERuBbwK8i4q/pem8HNgPH1KFPW4FOQD9AEbEkIlZnLDcGuDUiXoiIzcAPgWO1/bDddRGxNiLeBGaRs0dQgxckfQQsAZ7ik+GGXepXRCyLiMcjYnNElAOTSN6s62p82tfH0z3QlTt57WSZmNa2EbgfGCSpZ9o2BrgvfQ5PB5ZHxG/T19MLwL3AuWl/7oqIgVkPACDpIGAocFdEvA08wY57Eeelr6UVJHvQZ6XrfiYiOu/ktisnZnQkGerKtY7k9ZVPe7PlgGiEJO0B/I5kK+WSnPmPKDlw96GkMSRbmm9EREUe6/yepCXpcMxakj2DLmnzeJKtoZeVDCOdns7/HfAYMF3Jwb7/SIOrJmel/6Q9I+Ki9I2m0oqc33sC38vd8kv7cmC+fYqIJ4FfAL8E3pZ0i6S9MxY9kGSrvfJ+H5LsaXTLWeatnN83kLwhIGlxzvM9JGeZI9NlRpLsFe21O/2S1FXSdCUHvdcDd/LJ36YuegB/34X7Var6G6Vb038ARqWzRpFssEDSz6Or9XMMyTBQPr4GLImIBen0VOAr1V5b96Svpa4RcWJEzNulHuXnQ6D6a2dv4IM825stB0Qjk45/TyE5GHZOOgYLQEScFhEd09tUkn/og1TLQcX0ze0HJMMn+0ZEZ5ItIKXrXRoRo0mGC35KcoBur4jYGhFXR0R/4LMkW45jd7FruZcNXgFcW23Lb8+ImJZvn9K6b4yIo0iGAD5NMrRS3SqSNzSg6uDofsDKPNb/mZzn+y/V2iIi7gGeA/5lN/v1E5LnZ2A6zPdV0r9NHa0gGSLM8hGwZ8501pt59Us7TwNGKzmDqAPJ3lXl4/y5Wj87RsSFedY5FjhY0luS3iLZY+oC1HrGnqQhOaGddRtS2zoyLE7ryd0jOIJPhnYXp9OVNRxMsgf+6i48VpPigGh8biYZBz6j2hZ4lueB1cB1kvZSclD5cxnLdQIqgHKgtaR/IWeLSNJXJZVExMckBw4BtkkaKunwdPx8Pcmwzrbd6Vzq18AESUcrsZekL6X/oHn1SdI/pfdvQ/Lmt6mG2u4CxkkalI5n/zvw14hYXg/9ALgOOF/SP+xGvzqRbKWuldSN7KDLxxSSvp4kaQ9J3ZQcJwFYAIyS1EZSKelwUC0eJgnXfyU5q+jjdP7vgU9L+lq6vjbp3+Ow2laYhs0hJENug9LbAJK/U40HqytFxF9yQjvrVhXkSo6xtUsn2+mTY27V1/kqyfNzVfp3ORsYSDJsBskezhlpOO2VPh/3xfbHLJolB0Qjko73XkDyT/NWteGkHUTENuAMoA/wJlBGMuxR3WMkZxW9SjLcsonth3xOBRZL+pDkgPWoiNhEspU5gyQclpAcV9jtD2lFxFyS8fpfAO+THOT9Rh37tDfJG/L7aZ/WAD/LeKwnSM46uZfkDfoQPhk22W0R8RLJ8/L93ejX1STDVutIhnXu28VangfGAT9P1/VnPtl7+jFJ399PH++uPNa3Oa3lC7nLp2+MJ5M8j6tIhuh+SvpmrOQDjZknVpCEwIMR8VJEvFV5I3ndna76/XzBRpLgBXiZnBMslHyYcnLOsqOAUpLn5zrg3PR4EBGxmOQEjanAOySBflE91tloKfyFQWZmlsF7EGZmlskBYWZmmRwQZmaWyQFhZmaZmsOF06p06dIlevXqVewyzMyajHnz5r0bESVZbc0qIHr16sXcuXOLXYaZWZMh6Y2a2jzEZGZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmQoWEJJulfSOpEU1tEvSjZKWSVoo6chq7a0kzZf0+0LVaGZmNSvkHsRtwKk7aT8N6Jvezgdurtb+HWBJQSozM7NaFSwgIuJp4L2dLDIcuCMSs4HOkg4AkNQd+BLwm0LVZ2ZmO1fMYxDdgBU502XpPIDrgf8LfFzbSiSdL2mupLnl5eX1XqSZWUtVzIBQxryQdDrwTkTMy2clEXFLRJRGRGlJSUn9Vmhm1oIVMyDKgB45092BVcDngDMlLQemAydKurPhyzMza9mKGRAPAWPTs5mOAdZFxOqI+GFEdI+IXsAo4MmI+GoR6zQza5FaF2rFkqYBJwBdJJUBVwFtACJiMvAwMAxYBmwAxhWqFjMzq7uCBUREjK6lPYCLa1nmKeCp+qvKzMzy5U9Sm5lZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZSpYQEi6VdI7khbV0C5JN0paJmmhpCPT+T0kzZK0RNJiSd8pVI1mZlazQu5B3AacupP204C+6e184OZ0fgXwvYg4DDgGuFhS/wLWaWZmGQoWEBHxNPDeThYZDtwRidlAZ0kHRMTqiHghXccHwBKgW6HqNDOzbMU8BtENWJEzXUa1IJDUC/hH4K8NV5aZmUFxA0IZ86KqUeoI3Av8n4hYX+NKpPMlzZU0t7y8vABlmpm1TMUMiDKgR850d2AVgKQ2JOEwNSLu29lKIuKWiCiNiNKSkpKCFWtm1tIUMyAeAsamZzMdA6yLiNWSBEwBlkTEpCLWZ2bWorUu1IolTQNOALpIKgOuAtoARMRk4GFgGLAM2ACMS+/6OeBrwEuSFqTzroyIhwtVq5mZ7ahgARERo2tpD+DijPnPkH18wszMGpA/SW1mZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmfL6PghJnwMmAj3T+4jkKx0OLlxpZmZWTPl+YdAU4DJgHrCtcOWYmVljkW9ArIuIRwpaiZmZNSr5BsQsSf8fuA/YXDkzIl4oSFVmZlZ0+QbE0enP0px5AZxYv+WYmVljkVdARMTQQhdiZmaNS16nuUraR9IkSXPT239K2qfQxZmZWfHk+zmIW4EPgPPS23rgt4UqyszMii/fYxCHRMQ5OdNXS1pQgHrMzKyRyHcPYqOk4yon0g/ObSxMSWZm1hjkuwdxIXB7etxBwHvANwpVlJmZFV++ZzEtAI6QtHc6vb6QRZmZWfHtNCAkfTUi7pT03WrzAYiISQWszczMiqi2PYi90p+dCl2ImZk1LjsNiIj4Vfrz6oYpx8zMGot8Pyj3H5L2ltRG0hOS3pX01UIXZ2ZmxZPvaa4npwemTwfKgE8D39/ZHSTdKukdSYtqaJekGyUtk7RQ0pE5badKeiVtuyLPGs3MrB7lGxBt0p/DgGkR8V4e97kNOHUn7acBfdPb+cDNAJJaAb9M2/sDoyX1z7NOMzOrJ/l+DmKmpJdJPhx3kaQSYNPO7hART0vqtZNFhgN3REQAsyV1lnQA0AtYFhGvAUiani77tzxrrbOrZy7mb6t85q6ZNU39D9ybq874TL2vN689iIi4AjgWKI2IrcBHJG/au6MbsCJnuiydV9P8TJLOr7yIYHl5+W6WZGZmlWr7HMSJEfGkpBE583IXuW83HlsZ82In8zNFxC3ALQClpaU1LrczhUheM7OmrrYhps8DTwJnZLQFuxcQZUCPnOnuwCqgbQ3zzcysAdX2OYir0p/jCvDYDwGXpMcYjib53uvVksqBvpJ6AyuBUcBXCvD4Zma2E/l+DuLfJXXOmd5X0jW13Gca8BxwqKQySeMlTZA0IV3kYeA1YBnwa+AigIioAC4BHgOWAPdExOK6dcvMzHaXkpOIallImh8R/1ht3gsRcWRN9ymG0tLSmDt3brHLMDNrMiTNi4jSrLZ8PwfRSlK7nBV2ANrtZHkzM2vi8v0cxJ3AE5J+S3Jw+p+B2wtWlZmZFV2+3wfxH5IWAl8gOQ313yLisYJWZmZmRZXvHgQkB4wrIuJPkvaU1CkiPihUYWZmVlz5nsX0LWAG8Kt0VjfggQLVZGZmjUC+B6kvBj4HrAeIiKVA10IVZWZmxZdvQGyOiC2VE5Jas5PLX5iZWdOXb0D8WdKVQAdJXwT+G5hZuLLMzKzY8g2IHwDlwEvABSSfgv5RoYoyM7Piq/UsJkl7AAsjYgDJJTHMzKwFqHUPIiI+Bl6UdFAD1GNmZo1Evp+DOABYLOl5ki8LAiAizixIVWZmVnT5BsTVBa3CzMwandq+Ua49MAHoQ3KAekp6OW4zM2vmajsGcTtQShIOpwH/WfCKzMysUahtiKl/RBwOIGkK8HzhSzIzs8agtj2IrZW/eGjJzKxlqW0P4ghJ69PfRfJJ6vXp7xERexe0OjMzK5qdBkREtGqoQszMrHHJ91IbZmbWwjggzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDIVNCAknSrpFUnLJF2R0b6vpPslLZT0vKQBOW2XSVosaZGkaemXF5mZWQMpWEBIagX8kuSLhvoDoyX1r7bYlcCCiBgIjAVuSO/bDbgUKI2IAUArYFShajUzsx0Vcg9iMLAsIl6LiC3AdGB4tWX6A08ARMTLQC9J+6dtrUkuL94a2BNYVcBazcysmkIGRDdgRc50WTov14vACABJg4GeQPeIWAn8DHgTWA2si4g/FrBWMzOrppABoYx5UW36OmBfSQuAbwPzgQpJ+5LsbfQGDgT2kvTVzAeRzpc0V9Lc8vLyeivezKylK2RAlAE9cqa7U22YKCLWR8S4iBhEcgyiBHgd+ALwekSUR8RW4D7gs1kPEhG3RERpRJSWlJQUoBtmZi1TIQNiDtBXUm9JbUkOMj+Uu4CkzmkbwDeBpyNiPcnQ0jGS9pQk4CRgSQFrNTOzamr7TupdFhEVki4BHiM5C+nWiFgsaULaPhk4DLhD0jbgb8D4tO2vkmYALwAVJENPtxSqVjMz25Eiqh8WaLpKS0tj7ty5xS7DzKzJkDQvIkqz2vxJajMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0wOCDMzy1TQgJB0qqRXJC2TdEVG+76S7pe0UNLzkgbktHWWNEPSy5KWSDq2kLWamdn2ChYQkloBvwROA/oDoyX1r7bYlcCCiBgIjAVuyGm7AXg0IvoBRwBLClWrmZntqJB7EIOBZRHxWkRsAaYDw6st0x94AiAiXgZ6Sdpf0t7A8cCUtG1LRKwtYK1mZlZNIQOiG7AiZ7osnZfrRWAEgKTBQE+gO3AwUA78VtJ8Sb+RtFfWg0g6X9JcSXPLy8vruw9mZi1WIQNCGfOi2vR1wL6SFgDfBuYDFUBr4Ejg5oj4R+AjYIdjGAARcUtElEZEaUlJSX3VbmbW4rUu4LrLgB45092BVbkLRMR6YByAJAGvp7c9gbKI+Gu66AxqCAgzMyuMQu5BzAH6SuotqS0wCngod4H0TKW26eQ3gacjYn1EvAWskHRo2nYS8LcC1mpmZtUUbA8iIiokXQI8BrQCbo2IxZImpO2TgcOAOyRtIwmA8Tmr+DYwNQ2Q10j3NMzMrGEoovphgaartLQ05s6dW+wyzMyaDEnzIqI0q82fpDYzs0yFPEjdKGzdupWysjI2bdpU7FKsCWvfvj3du3enTZs2xS7FrME0+4AoKyujU6dO9OrVi+REKbO6iQjWrFlDWVkZvXv3LnY5Zg2m2Q8xbdq0if3228/hYLtMEvvtt5/3Qq3FafYBATgcbLf5NWQtUYsICDMzqzsHRAPo2LHjDvMmT57MHXfcUfDHvvXWWzn88MMZOHAgAwYM4MEHH+S2225j9OjR2y337rvvUlJSwubNm9m6dStXXHEFffv2ZcCAAQwePJhHHnkkc/3nnnsur732WtX0/PnzkcRjjz223XKtWrVi0KBBDBgwgC9/+cts2LBht/r18ssvc+yxx9KuXTt+9rOf1bjc66+/ztFHH03fvn0ZOXIkW7ZsAZLjCpdeeil9+vRh4MCBvPDCCwBs2bKF448/noqKit2qz6w5cEAUyYQJExg7dmzB1h8RvPnmm1x77bU888wzLFy4kNmzZzNw4EBGjBjB448/vt2b9IwZMzjzzDNp164dP/7xj1m9ejWLFi1i0aJFzJw5kw8++GCHx1i8eDHbtm3j4IMPrpo3bdo0jjvuOKZNm7bdsh06dGDBggUsWrSItm3bMnny5N3q36c+9SluvPFGLr/88p0u94Mf/IDLLruMpUuXsu+++zJlyhQAHnnkEZYuXcrSpUu55ZZbuPDCCwFo27YtJ510Enffffdu1WfWHDT7s5hyXT1zMX9btb5e19n/wL256ozP1Pl+EydOpGPHjlx++eWccMIJHH300cyaNYu1a9cyZcoUhgwZwrZt27jiiit46qmn2Lx5MxdffDEXXHABH374IcOHD+f9999n69atXHPNNQwfPpzly5dz2mmnMXToUJ577jmuv/56OnXqVLUH07Fjx6rfjz/+eGbOnMnIkSMBmD59Oj/60Y/YsGEDv/71r3n99ddp164dAPvvvz/nnXfeDn2YOnUqw4d/cgX3iGDGjBk8/vjjDBkyhE2bNtG+ffsd7jdkyBAWLlxY5+csV9euXenatSt/+MMfalwmInjyySe56667APj617/OxIkTufDCC3nwwQcZO3YskjjmmGNYu3Ytq1ev5oADDuCss87ihz/8IWPGjNmtGs2aOu9BNBIVFRU8//zzXH/99Vx99dUATJkyhX322Yc5c+YwZ86cqjfu9u3bc//99/PCCy8wa9Ysvve971H5ifhXXnmFsWPHMn/+fI477jj2339/evfuzbhx45g5c2bV440ePZrp06cDsGrVKl599VWGDh3KsmXLOOigg9h7771rrfnZZ5/lqKOO2m66d+/eHHLIIZxwwgk8/PDDmf185JFHOPzww3doGzlyJIMGDdrhtqtDcWvWrKFz5860bp1sB3Xv3p2VK1cCsHLlSnr0+ORakrltAwYMYM6cObv0mGbNSYvag9iVLf2GMmLECACOOuooli9fDsAf//hHFi5cyIwZMwBYt24dS5cupXv37lx55ZU8/fTT7LHHHqxcuZK3334bgJ49e3LMMccAybj/o48+ypw5c3jiiSe47LLLmDdvHhMnTuT000/noosuYv369dxzzz2ce+65tGrVqk41r169mtxLrE+bNo1Ro0YBMGrUKH73u99V9Wvjxo0MGjQISPYgxo8fv8P66ntYJ+syMpVnI+2srVWrVrRt25YPPviATp061WtNZk1JiwqIxqxyOKdVq1ZVB0gjgv/6r//ilFNO2W7Z2267jfLycubNm0ebNm3o1atX1Tn6e+21/fcqSWLw4MEMHjyYL37xi4wbN46JEyfSoUMHTj31VO6//36mT5/Oz3/+cwD69OnDm2++mdebY4cOHaoed9u2bdx777089NBDXHvttVUfLqtcT+UxiJ0ZOXIkr7zyyg7zv/vd7+7S8ZouXbqwdu1aKioqaN26NWVlZRx44IFAssewYsUn32eV2wawefPmzOExs5bEQ0yN2CmnnMLNN9/M1q1bAXj11Vf56KOPWLduHV27dqVNmzbMmjWLN954I/P+q1atqjo7B2DBggX07Nmzanr06NFMmjSJt99+u2qvY88992T8+PFceumlVWf8rF69mjvvvHOH9R922GEsW7YMgD/96U8cccQRrFixguXLl/PGG29wzjnn8MADD+Td37vvvpsFCxbscNvVg/mSGDp0aNUe2O233151zOTMM8/kjjvuICKYPXs2++yzDwcccACQDE2VlJT4shrW4jkgGsCGDRvo3r171W3SpEl53e+b3/wm/fv358gjj2TAgAFccMEFVFRUMGbMGObOnUtpaSlTp06lX79+mfffunUrl19+Of369WPQoEHcfffd3HDDDVXtJ598MqtWrWLkyJHbfRDsmmuuoaSkhP79+zNgwADOOusssr6t70tf+hJPPfUUkAwvnX322du1n3POOVUHiOvbW2+9VfVcXnPNNXTv3p3165MTEIYNG8aqVcl3U/30pz9l0qRJ9OnThzVr1lQNbQ0bNoyDDz6YPn368K1vfYubbrqpat2zZs1i2LBhBanbrClp9pf7XrJkCYcddliRKmreNm7cyNChQ3n22WfrfPyiMRsxYgQ/+clPOPTQQ7eb79eSNUe+3LcVRIcOHbj66qurzv5pDrZs2cJZZ521QziYtUQ+SG27pfoB9Kaubdu2Bf0Ao1lT0iL2IJrTMJoVh19D1hI1+4Bo3749a9as8T+47bLKU3Z92qu1NM1+iKl79+6UlZVRXl5e7FKsCav8RjmzlqTZB0SbNm38LWBmZrug2Q8xmZnZrnFAmJlZJgeEmZllalafpJZUDmRfmKh2XYB367GcpsB9bv5aWn/Bfa6rnhGx47V0aGYBsTskza3p4+bNlfvc/LW0/oL7XJ88xGRmZpkcEGZmlskB8Ylbil1AEbjPzV9L6y+4z/XGxyDMzCyT9yDMzCyTA8LMzDK1qICQdKqkVyQtk3RFRrsk3Zi2L5R0ZDHqrE959HlM2teFkv5H0hHFqLM+1dbnnOX+SdI2Sec2ZH2FkE+fJZ0gaYGkxZL+3NA11rc8Xtv7SJop6cW0z+OKUWd9kXSrpHckLaqhvf7fvyKiRdyAVsDfgYOBtsCLQP9qywwDHgEEHAP8tdh1N0CfPwvsm/5+Wkvoc85yTwIPA+cWu+4G+Dt3Bv4GHJROdy123Q3Q5yuBn6a/lwDvAW2LXftu9Pl44EhgUQ3t9f7+1ZL2IAYDyyLitYjYAkwHhldbZjhwRyRmA50lHdDQhdajWvscEf8TEe+nk7OBpn5N63z+zgDfBu4F3mnI4goknz5/BbgvIt4EiIim3u98+hxAJ0kCOpIEREXDlll/IuJpkj7UpN7fv1pSQHQDVuRMl6Xz6rpMU1LX/own2QJpymrts6RuwNnA5Aasq5Dy+Tt/GthX0lOS5klq6t+rmk+ffwEcBqwCXgK+ExEfN0x5RVHv71/N/vsgcihjXvVzfPNZpinJuz+ShpIExHEFrajw8unz9cAPImJbsnHZ5OXT59bAUcBJQAfgOUmzI+LVQhdXIPn0+RRgAXAicAjwuKS/RMT6AtdWLPX+/tWSAqIM6JEz3Z1ky6KuyzQlefVH0kDgN8BpEbGmgWorlHz6XApMT8OhCzBMUkVEPNAgFda/fF/b70bER8BHkp4GjgCaakDk0+dxwHWRDNAvk/Q60A94vmFKbHD1/v7VkoaY5gB9JfWW1BYYBTxUbZmHgLHp2QDHAOsiYnVDF1qPau2zpIOA+4CvNeGtyVy19jkiekdEr4joBcwALmrC4QD5vbYfBIZIai1pT+BoYEkD11mf8unzmyR7TEjaHzgUeK1Bq2xY9f7+1WL2ICKiQtIlwGMkZ0DcGhGLJU1I2yeTnNEyDFgGbCDZAmmy8uzzvwD7ATelW9QV0YSvhJlnn5uVfPocEUskPQosBD4GfhMRmadLNgV5/p3/DbhN0kskwy8/iIgmexlwSdOAE4AuksqAq4A2ULj3L19qw8zMMrWkISYzM6sDB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEWR2kV39dIGlReqXQzvW8/uWSuqS/f1if6zarKweEWd1sjIhBETGA5MJpFxe7ILNCcUCY7brnSC+GJukQSY+mF8L7i6R+6fz9Jd2ffifBi5I+m85/IF12saTzi9gHsxq1mE9Sm9UnSa1ILuMwJZ11CzAhIpZKOhq4ieQicTcCf46Is9P7dEyX/+eIeE9SB2COpHubwXWwrJlxQJjVTQdJC4BewDySK4R2JPnipf/OuTpsu/TnicBYgIjYBqxL518q6ez09x5AX8ABYY2KA8KsbjZGxCBJ+wC/JzkGcRuwNiIG5bMCSScAXwCOjYgNkp4C2heiWLPd4WMQZrsgItYBlwKXAxuB1yV9Gaq+G7jyu72fAC5M57eStDewD/B+Gg79SL4e0qzRcUCY7aKImE/yXcijgDHAeEkvAov55OsvvwMMTa8oOg/4DPAo0FrSQpIrjs5u6NrN8uGruZqZWSbvQZiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWab/BavsAaYLnSjsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(classifier, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, validation_curve\n",
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=5,random_state=7)\n",
    "\n",
    "cv_results = cross_val_score(logreg, X_train,y_train, cv=kfold)\n",
    "print (cv_results.mean()*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative method for multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression    #Logistic Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_digits()\n",
    "features = digits.data\n",
    "target = digits.target\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "F:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Create one-vs-rest logistic regression object\n",
    "log_reg = LogisticRegression(random_state=0, multi_class=\"ovr\") #multi_class='multinomial'\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred=log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0       1          8\n",
       "1       0          0\n",
       "2       9          9\n",
       "3       1          1\n",
       "4       5          5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_predicted=pd.DataFrame()\n",
    "df_predicted['Actual']=y_test\n",
    "df_predicted['Predicted']=y_pred\n",
    "df_predicted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mislabelled data points from 450 test samples is 18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mislabel = np.sum((y_test!=y_pred))\n",
    "print(\"Total number of mislabelled data points from {} test samples is {}\".format(len(y_test),mislabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set= 96.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of test set=\",accuracy_score(y_test, y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix looks like following...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9\n",
       "0  44   0   0   0   1   0   0   0   0   0\n",
       "1   0  43   0   1   0   0   1   0   1   0\n",
       "2   0   1  43   0   0   0   0   0   0   0\n",
       "3   0   0   0  46   0   0   0   0   0   0\n",
       "4   0   0   0   0  45   0   0   0   0   0\n",
       "5   0   0   0   0   0  45   0   0   0   1\n",
       "6   0   1   0   0   0   0  43   0   1   0\n",
       "7   0   0   0   0   1   0   0  44   0   0\n",
       "8   0   5   0   0   0   0   0   0  38   0\n",
       "9   1   0   0   0   0   0   0   1   2  41"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = (confusion_matrix(y_test,y_pred))\n",
    "cmdf = pd.DataFrame(cm,index=digits.target_names, columns=digits.target_names)\n",
    "print(\"The confusion matrix looks like following...\\n\")\n",
    "cmdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08444444444444445"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create dummy classifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "# \"Train\" model\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy score\n",
    "dummy.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
